
export const allModels = [
    {
        id: "gemini-1.5-flash",
        name: "Google: Gemini 1.5 Flash",
        description: "Google's fastest and most cost-effective multimodal model.",
        context: "1M tokens",
        openRouterId: null,
        genkitId: 'googleai/gemini-1.5-flash-latest',
        useCases: ["Dialogue", "Creative Writing", "Summarization", "Image Analysis"],
    },
    {
        id: "gemini-1.5-pro",
        name: "Google: Gemini 1.5 Pro",
        description: "Google's flagship model, with a massive context window and advanced multimodal reasoning.",
        context: "1M tokens",
        openRouterId: null,
        genkitId: 'googleai/gemini-1.5-pro-latest',
        useCases: ["Dialogue", "Creative Writing", "Summarization", "Image Analysis", "Coding"],
    },
    {
        id: "gemini-1.0-pro",
        name: "Google: Gemini 1.0 Pro",
        description: "The original Pro-grade Gemini model, balanced for performance and cost.",
        context: "32K tokens",
        openRouterId: null,
        genkitId: 'googleai/gemini-1.0-pro',
        useCases: ["Dialogue", "Creative Writing", "Summarization"],
    },
    {
        id: "openai-gpt-4o",
        name: "OpenAI: GPT-4o",
        description: "OpenAI's newest, most advanced flagship model that is cheaper and faster than GPT-4 Turbo.",
        context: "128K tokens",
        openRouterId: "openai/gpt-4o",
        genkitId: null,
        useCases: ["Dialogue", "Creative Writing", "Summarization", "Image Analysis", "Coding"],
    },
    {
        id: "openai-gpt-4-turbo",
        name: "OpenAI: GPT-4 Turbo",
        description: "The Turbo model from OpenAI, with a large context window and strong performance.",
        context: "128K tokens",
        openRouterId: "openai/gpt-4-turbo",
        genkitId: null,
        useCases: ["Dialogue", "Creative Writing", "Summarization", "Coding"],
    },
    {
        id: "anthropic-claude-3-opus",
        name: "Anthropic: Claude 3 Opus",
        description: "Anthropic's most powerful model for highly complex tasks.",
        context: "200K tokens",
        openRouterId: "anthropic/claude-3-opus",
        genkitId: null,
        useCases: ["Dialogue", "Creative Writing", "Summarization", "Coding"],
    },
    {
        id: "anthropic-claude-3-sonnet",
        name: "Anthropic: Claude 3 Sonnet",
        description: "A balanced model between intelligence and speed, great for enterprise workloads.",
        context: "200K tokens",
        openRouterId: "anthropic/claude-3-sonnet",
        genkitId: null,
        useCases: ["Dialogue", "Creative Writing", "Summarization", "Coding"],
    },
    {
        id: "anthropic-claude-3-haiku",
        name: "Anthropic: Claude 3 Haiku",
        description: "The fastest and most compact model for near-instant responsiveness.",
        context: "200K tokens",
        openRouterId: "anthropic/claude-3-haiku",
        genkitId: null,
        useCases: ["Dialogue", "Summarization"],
    },
    {
        id: "llama",
        name: "Meta: Llama 3 8B Instruct",
        description: "The 8B instruction-tuned version of Meta's Llama 3 model.",
        context: "8K tokens",
        openRouterId: "meta-llama/llama-3-8b-instruct",
        useCases: ["Dialogue", "Creative Writing", "Summarization", "Coding"],
    },
    {
        id: "mistral-7b",
        name: "Mistral: Mistral 7B Instruct (free)",
        description: "The 7B instruction-tuned model from Mistral AI.",
        context: "32K tokens",
        openRouterId: "mistralai/mistral-7b-instruct",
        useCases: ["Dialogue", "Creative Writing", "Summarization"],
    },
    {
        id: "deepseek-chat",
        name: "DeepSeek: DeepSeek Chat",
        description: "A chat model from DeepSeek AI, specializing in conversation.",
        context: "32K tokens",
        openRouterId: "deepseek/deepseek-chat",
        useCases: ["Dialogue"],
    },
    {
        id: "mistral-small",
        name: "Mistral: Mistral Small (free)",
        description: "A small, efficient model from Mistral AI, great for simple tasks.",
        context: "32K tokens",
        openRouterId: "mistralai/mistral-small",
        useCases: ["Dialogue", "Summarization"],
    },
    {
        id: "qwen-qwen2-72b-instruct",
        name: "Qwen: Qwen2 72B Instruct (free)",
        description: "The 72B parameter model from Qwen, with strong coding, math and long-context support.",
        context: "128K context",
        openRouterId: "qwen/qwen2-72b-instruct",
        useCases: ["Dialogue", "Coding"],
    },
    {
        id: "meta-llama-3-1-405b-instruct",
        name: "Meta: Llama 3.1 405B Instruct (free)",
        description: "The highly anticipated 405B parameter Llama 3.1 model, optimized for high-quality dialogue.",
        context: "128K context",
        openRouterId: "meta-llama/llama-3.1-405b-instruct",
        useCases: ["Dialogue", "Creative Writing", "Summarization", "Coding"],
    },
    {
        id: "mistral-nemo",
        name: "Mistral: Mistral Nemo (free)",
        description: "A 12B parameter model with a 128k token context length built by Mistral and NVIDIA.",
        context: "128K context",
        openRouterId: "mistralai/mistral-nemo",
        useCases: ["Dialogue", "Coding"],
    },
    {
        id: "google-gemma-2-9b",
        name: "Google: Gemma 2 9B (free)",
        description: "An advanced, open-source 9B parameter model from Google, setting new standards for its size class.",
        context: "8K context",
        openRouterId: "google/gemma-2-9b-instruct",
        useCases: ["Dialogue", "Coding", "Summarization"],
    },
    {
        id: "nvidia-nemotron-4-340b-instruct",
        name: "Nvidia: Nemotron-4 340B Instruct",
        description: "NVIDIA's powerful Nemotron-4 340B model, adapted for instruction-following.",
        context: "4K context",
        openRouterId: "nvidia/nemotron-4-340b-instruct",
        useCases: ["Dialogue", "Coding"],
    }
];
