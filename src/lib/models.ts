
export const allModels = [
    {
        id: "gemini-1.5-flash",
        name: "Google: Gemini 1.5 Flash",
        description: "Google's fastest and most cost-effective multimodal model.",
        context: "1M tokens",
        openRouterId: null,
        genkitId: 'googleai/gemini-1.5-flash-latest',
        useCases: ["Dialogue", "Creative Writing", "Summarization", "Image Analysis"],
    },
    {
        id: "gemini-1.5-pro",
        name: "Google: Gemini 1.5 Pro",
        description: "Google's flagship model, with a massive context window and advanced multimodal reasoning.",
        context: "1M tokens",
        openRouterId: null,
        genkitId: 'googleai/gemini-1.5-pro-latest',
        useCases: ["Dialogue", "Creative Writing", "Summarization", "Image Analysis", "Coding"],
    },
    {
        id: "gemini-1.0-pro",
        name: "Google: Gemini 1.0 Pro",
        description: "The original Pro-grade Gemini model, balanced for performance and cost.",
        context: "32K tokens",
        openRouterId: null,
        genkitId: 'googleai/gemini-1.0-pro',
        useCases: ["Dialogue", "Creative Writing", "Summarization"],
    },
    {
        id: "llama",
        name: "Meta: Llama 3 8B Instruct",
        description: "The 8B instruction-tuned version of Meta's Llama 3 model.",
        context: "8K tokens",
        openRouterId: "meta-llama/llama-3-8b-instruct",
        useCases: ["Dialogue", "Creative Writing", "Summarization", "Coding"],
    },
    {
        id: "mistral-7b",
        name: "Mistral: Mistral 7B Instruct (free)",
        description: "The 7B instruction-tuned model from Mistral AI.",
        context: "32K tokens",
        openRouterId: "mistralai/mistral-7b-instruct",
        useCases: ["Dialogue", "Creative Writing", "Summarization"],
    },
    {
        id: "deepseek-chat",
        name: "DeepSeek: DeepSeek Chat",
        description: "A chat model from DeepSeek AI, specializing in conversation.",
        context: "32K tokens",
        openRouterId: "deepseek/deepseek-chat",
        useCases: ["Dialogue"],
    },
    {
        id: "mistral-small",
        name: "Mistral: Mistral Small (free)",
        description: "A small, efficient model from Mistral AI, great for simple tasks.",
        context: "32K tokens",
        openRouterId: "mistralai/mistral-small",
        useCases: ["Dialogue", "Summarization"],
    },
    {
        id: "qwen-qwen2-72b-instruct",
        name: "Qwen: Qwen2 72B Instruct (free)",
        description: "The 72B parameter model from Qwen, with strong coding, math and long-context support.",
        context: "128K context",
        openRouterId: "qwen/qwen2-72b-instruct",
        useCases: ["Dialogue", "Coding"],
    },
    {
        id: "meta-llama-3-1-405b-instruct",
        name: "Meta: Llama 3.1 405B Instruct (free)",
        description: "The highly anticipated 405B parameter Llama 3.1 model, optimized for high-quality dialogue.",
        context: "128K context",
        openRouterId: "meta-llama/llama-3.1-405b-instruct",
        useCases: ["Dialogue", "Creative Writing", "Summarization", "Coding"],
    },
    {
        id: "mistral-nemo",
        name: "Mistral: Mistral Nemo (free)",
        description: "A 12B parameter model with a 128k token context length built by Mistral and NVIDIA.",
        context: "128K context",
        openRouterId: "mistralai/mistral-nemo",
        useCases: ["Dialogue", "Coding"],
    },
    {
        id: "google-gemma-2-9b",
        name: "Google: Gemma 2 9B (free)",
        description: "An advanced, open-source 9B parameter model from Google, setting new standards for its size class.",
        context: "8K context",
        openRouterId: "google/gemma-2-9b-instruct",
        useCases: ["Dialogue", "Coding", "Summarization"],
    },
    {
        id: "nvidia-nemotron-4-340b-instruct",
        name: "Nvidia: Nemotron-4 340B Instruct",
        description: "NVIDIA's powerful Nemotron-4 340B model, adapted for instruction-following.",
        context: "4K context",
        openRouterId: "nvidia/nemotron-4-340b-instruct",
        useCases: ["Dialogue", "Coding"],
    },
    // Additional free OpenRouter models
    {
        id: "google-gemini-2-5-flash-image-preview-free",
        name: "Google: Gemini 2.5 Flash Image Preview (free)",
        description: "Gemini 2.5 Flash Image Preview is a state of the art image generation model with contextual understanding. It is capable of image generation, edits, and multi-turn conversations.",
        context: "32K tokens",
        openRouterId: "google/gemini-2.5-flash-image-preview:free",
        useCases: ["Image Analysis"],
    },
    {
        id: "openai-gpt-oss-20b-free",
        name: "OpenAI: gpt-oss-20b (free)",
        description: "gpt-oss-20b is an open-weight 21B parameter model released by OpenAI under the Apache 2.0 license. It uses a Mixture-of-Experts (MoE) architecture with 3.6B active parameters per forward pass, optimiz...",
        context: "131K tokens",
        openRouterId: "openai/gpt-oss-20b:free",
        useCases: ["Dialogue", "Coding"],
    },
    {
        id: "z-ai-glm-4-5-air-free",
        name: "Z.AI: GLM 4.5 Air (free)",
        description: "GLM-4.5-Air is the lightweight variant of our latest flagship model family, also purpose-built for agent-centric applications. Like GLM-4.5, it adopts the Mixture-of-Experts (MoE) architecture but wit...",
        context: "131K tokens",
        openRouterId: "z-ai/glm-4.5-air:free",
        useCases: ["Dialogue"],
    },
    {
        id: "qwen-qwen3-coder-free",
        name: "Qwen: Qwen3 Coder (free)",
        description: "Qwen3-Coder is a Mixture-of-Experts (MoE) code generation model developed by the Qwen team. It is optimized for agentic coding tasks such as function calling, tool use, and long-con...",
        context: "262K tokens",
        openRouterId: "qwen/qwen3-coder:free",
        useCases: ["Coding"],
    },
    {
        id: "moonshotai-kimi-k2-free",
        name: "MoonshotAI: Kimi K2 (free)",
        description: "Kimi K2 Instruct is a large-scale Mixture-of-Experts (MoE) language model developed by Moonshot AI, featuring 1 trillion total parameters with 32 billion active per forward pass. It is optimized for a...",
        context: "32K tokens",
        openRouterId: "moonshotai/kimi-k2:free",
        useCases: ["Dialogue", "Creative Writing"],
    },
    {
        id: "cognitivecomputations-dolphin-mistral-24b-venice-edition-free",
        name: "Venice: Uncensored (free)",
        description: "Venice Uncensored Dolphin Mistral 24B Venice Edition is a fine-tuned variant of Mistral-Small-24B-Instruct-2501, developed by dphn.ai in collaboration with Venice.ai. This model is designed as an âu...",
        context: "32K tokens",
        openRouterId: "cognitivecomputations/dolphin-mistral-24b-venice-edition:free",
        useCases: ["Creative Writing"],
    },
    {
        id: "google-gemma-3n-e2b-it-free",
        name: "Google: Gemma 3n 2B (free)",
        description: "Gemma 3n E2B IT is a multimodal, instruction-tuned model developed by Google DeepMind, designed to operate efficiently at an effective parameter size of 2B while leveraging a 6B architecture. Based on...",
        context: "8K tokens",
        openRouterId: "google/gemma-3n-e2b-it:free",
        useCases: ["Dialogue", "Image Analysis"],
    },
    {
        id: "tencent-hunyuan-a13b-instruct-free",
        name: "Tencent: Hunyuan A13B Instruct (free)",
        description: "Hunyuan-A13B is a 13B active parameter Mixture-of-Experts (MoE) language model developed by Tencent, with a total parameter count of 80B and support for reasoning via Chain-of-Thought. It offers compe...",
        context: "32K tokens",
        openRouterId: "tencent/hunyuan-a13b-instruct:free",
        useCases: ["Dialogue"],
    },
    {
        id: "tngtech-deepseek-r1t2-chimera-free",
        name: "TNG: DeepSeek R1T2 Chimera (free)",
        description: "DeepSeek-TNG-R1T2-Chimera is the second-generation Chimera model from TNG Tech. It is a 671 B-parameter mixture-of-experts text-generation model assembled from DeepSeek-AIâs R1-0528, R1, and V3-0324...",
        context: "163K tokens",
        openRouterId: "tngtech/deepseek-r1t2-chimera:free",
        useCases: ["Dialogue", "Creative Writing"],
    },
    {
        id: "mistralai-mistral-small-3-2-24b-instruct-free",
        name: "Mistral: Mistral Small 3.2 24B (free)",
        description: "Mistral-Small-3.2-24B-Instruct-2506 is an updated 24B parameter model from Mistral optimized for instruction following, repetition reduction, and improved function calling. Compared to the 3.1 release...",
        context: "131K tokens",
        openRouterId: "mistralai/mistral-small-3.2-24b-instruct:free",
        useCases: ["Dialogue", "Coding"],
    },
    {
        id: "moonshotai-kimi-dev-72b-free",
        name: "MoonshotAI: Kimi Dev 72B (free)",
        description: "Kimi-Dev-72B is an open-source large language model fine-tuned for software engineering and issue resolution tasks. Based on Qwen2.5-72B, it is optimized using large-scale reinforcement learning that ...",
        context: "131K tokens",
        openRouterId: "moonshotai/kimi-dev-72b:free",
        useCases: ["Coding"],
    },
    {
        id: "deepseek-deepseek-r1-0528-qwen3-8b-free",
        name: "DeepSeek: Deepseek R1 0528 Qwen3 8B (free)",
        description: "DeepSeek-R1-0528 is a lightly upgraded release of DeepSeek R1 that taps more compute and smarter post-training tricks, pushing its reasoning and inference to the brink of flagship models like O3 and G...",
        context: "131K tokens",
        openRouterId: "deepseek/deepseek-r1-0528-qwen3-8b:free",
        useCases: ["Dialogue", "Creative Writing"],
    },
    {
        id: "deepseek-deepseek-r1-0528-free",
        name: "DeepSeek: R1 0528 (free)",
        description: "May 28th update to the [original DeepSeek R1](/deepseek/deepseek-r1) Performance on par with [OpenAI o1](/openai/o1), but open-sourced and with fully open reasoning tokens. It's 671B parameters in siz...",
        context: "163K tokens",
        openRouterId: "deepseek/deepseek-r1-0528:free",
        useCases: ["Dialogue", "Creative Writing"],
    },
    {
        id: "sarvamai-sarvam-m-free",
        name: "Sarvam AI: Sarvam-M (free)",
        description: "Sarvam-M is a 24 B-parameter, instruction-tuned derivative of Mistral-Small-3.1-24B-Base-2503, post-trained on English plus eleven major Indic languages (bn, hi, kn, gu, mr, ml, or, pa, ta, te). The m...",
        context: "32K tokens",
        openRouterId: "sarvamai/sarvam-m:free",
        useCases: ["Dialogue"],
    },
    {
        id: "mistralai-devstral-small-2505-free",
        name: "Mistral: Devstral Small 2505 (free)",
        description: "Devstral-Small-2505 is a 24B parameter agentic LLM fine-tuned from Mistral-Small-3.1, jointly developed by Mistral AI and All Hands AI for advanced software engineering tasks. It is optimized for code...",
        context: "32K tokens",
        openRouterId: "mistralai/devstral-small-2505:free",
        useCases: ["Coding"],
    },
    {
        id: "google-gemma-3n-e4b-it-free",
        name: "Google: Gemma 3n 4B (free)",
        description: "Gemma 3n E4B-it is optimized for efficient execution on mobile and low-resource devices, such as phones, laptops, and tablets. It supports multimodal inputsâincluding text, visual data, and audioâ...",
        context: "8K tokens",
        openRouterId: "google/gemma-3n-e4b-it:free",
        useCases: ["Dialogue", "Image Analysis"],
    },
    {
        id: "meta-llama-llama-3-3-8b-instruct-free",
        name: "Meta: Llama 3.3 8B Instruct (free)",
        description: "A lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response times are needed most.",
        context: "128K tokens",
        openRouterId: "meta-llama/llama-3.3-8b-instruct:free",
        useCases: ["Dialogue", "Summarization"],
    },
    {
        id: "qwen-qwen3-4b-free",
        name: "Qwen: Qwen3 4B (free)",
        description: "Qwen3-4B is a 4 billion parameter dense language model from the Qwen3 series, designed to support both general-purpose and reasoning-intensive tasks. It introduces a dual-mode architectureâthinking ...",
        context: "40K tokens",
        openRouterId: "qwen/qwen3-4b:free",
        useCases: ["Dialogue"],
    },
    {
        id: "qwen-qwen3-8b-free",
        name: "Qwen: Qwen3 8B (free)",
        description: "Qwen3-8B is a dense 8.2B parameter causal language model from the Qwen3 series, designed for both reasoning-heavy tasks and efficient dialogue. It supports seamless switching between \"thinking\" mode...",
        context: "40K tokens",
        openRouterId: "qwen/qwen3-8b:free",
        useCases: ["Dialogue"],
    },
    {
        id: "qwen-qwen3-14b-free",
        name: "Qwen: Qwen3 14B (free)",
        description: "Qwen3-14B is a dense 14.8B parameter causal language model from the Qwen3 series, designed for both complex reasoning and efficient dialogue. It supports seamless switching between a \"thinking\" mode...",
        context: "40K tokens",
        openRouterId: "qwen/qwen3-14b:free",
        useCases: ["Dialogue", "Coding"],
    },
    {
        id: "meta-llama-llama-4-maverick-free",
        name: "Meta: Llama 4 Maverick (free)",
        description: "Llama 4 Maverick 17B Instruct (128E) is a high-capacity multimodal language model from Meta, built on a mixture-of-experts (MoE) architecture with 128 experts and 17 billion active parameters per forw...",
        context: "128K tokens",
        openRouterId: "meta-llama/llama-4-maverick:free",
        useCases: ["Dialogue", "Image Analysis"],
    },
    {
        id: "meta-llama-llama-4-scout-free",
        name: "Meta: Llama 4 Scout (free)",
        description: "Llama 4 Scout 17B Instruct (16E) is a mixture-of-experts (MoE) language model developed by Meta, activating 17 billion parameters out of a total of 109B. It supports native multimodal input (text and ...",
        context: "128K tokens",
        openRouterId: "meta-llama/llama-4-scout:free",
        useCases: ["Dialogue", "Image Analysis"],
    },
    {
        id: "google-gemini-2-5-pro-exp-03-25",
        name: "Google: Gemini 2.5 Pro Experimental",
        description: "This model has been deprecated by Google in favor of the (paid Preview model)[google/gemini-2.5-pro-preview] Â  Gemini 2.5 Pro is Googleâs state-of-the-art AI model designed for advanced reasoning, ...",
        context: "1M tokens",
        openRouterId: "google/gemini-2.5-pro-exp-03-25",
        useCases: ["Dialogue", "Creative Writing", "Summarization", "Coding"],
    },
    {
        id: "qwen-qwen2-5-vl-32b-instruct-free",
        name: "Qwen: Qwen2.5 VL 32B Instruct (free)",
        description: "Qwen2.5-VL-32B is a multimodal vision-language model fine-tuned through reinforcement learning for enhanced mathematical reasoning, structured outputs, and visual problem-solving capabilities. It exce...",
        context: "8K tokens",
        openRouterId: "qwen/qwen2.5-vl-32b-instruct:free",
        useCases: ["Image Analysis"],
    },
    {
        id: "meta-llama-llama-3-2-3b-instruct-free",
        name: "Meta: Llama 3.2 3B Instruct (free)",
        description: "Llama 3.2 3B is a 3-billion-parameter multilingual large language model, optimized for advanced natural language processing tasks like dialogue generation, reasoning, and summarization. Designed with ...",
        context: "131K tokens",
        openRouterId: "meta-llama/llama-3.2-3b-instruct:free",
        useCases: ["Dialogue", "Summarization"],
    },
    {
        id: "qwen-qwen-2-5-72b-instruct-free",
        name: "Qwen2.5 72B Instruct (free)",
        description: "Qwen2.5 72B is the latest series of Qwen large language models. Qwen2.5 brings the following improvements upon Qwen2:  - Significantly more knowledge and has greatly improved capabilities in coding and...",
        context: "32K tokens",
        openRouterId: "qwen/qwen-2.5-72b-instruct:free",
        useCases: ["Dialogue", "Coding"],
    }
];
